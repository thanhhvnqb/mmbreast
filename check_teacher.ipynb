{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23370/1035187702.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n",
      "/home/islab/DATA/venv/mmbreast/lib/python3.12/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n",
      "/home/islab/DATA/venv/mmbreast/lib/python3.12/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.17 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/home/islab/DATA/venv/mmbreast/lib/python3.12/site-packages/mmcv/cnn/bricks/transformer.py:33: UserWarning: Fail to import ``MultiScaleDeformableAttention`` from ``mmcv.ops.multi_scale_deform_attn``, You should install ``mmcv`` rather than ``mmcv-lite`` if you need this module. \n",
      "  warnings.warn('Fail to import ``MultiScaleDeformableAttention`` from '\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "import pkg_resources\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from mmcv.transforms import Compose\n",
    "from mmengine.config import Config, DictAction\n",
    "from mmengine.dataset import default_collate\n",
    "from mmengine.utils import to_2tuple\n",
    "from mmengine.utils.dl_utils import is_norm\n",
    "\n",
    "from mmpretrain import digit_version\n",
    "from mmpretrain.apis import get_model\n",
    "from mmpretrain.registry import TRANSFORMS, DATASETS\n",
    "\n",
    "try:\n",
    "    import pytorch_grad_cam as cam\n",
    "    from pytorch_grad_cam.activations_and_gradients import \\\n",
    "        ActivationsAndGradients\n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "except ImportError:\n",
    "    raise ImportError('Please run `pip install \"grad-cam>=1.3.6\"` to install '\n",
    "                      '3rd party package pytorch_grad_cam.')\n",
    "\n",
    "from mmbreast import *\n",
    "\n",
    "# Alias name\n",
    "METHOD_MAP = {\n",
    "    'gradcam++': cam.GradCAMPlusPlus,\n",
    "}\n",
    "METHOD_MAP.update({\n",
    "    cam_class.__name__.lower(): cam_class\n",
    "    for cam_class in cam.base_cam.BaseCAM.__subclasses__()\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reshape_transform(tensor, model, vit_like=False, num_extra_tokens=None):\n",
    "    \"\"\"Build reshape_transform for `cam.activations_and_grads`, which is\n",
    "    necessary for ViT-like networks.\"\"\"\n",
    "    # ViT_based_Transformers have an additional clstoken in features\n",
    "    if tensor.ndim == 4:\n",
    "        # For (B, C, H, W)\n",
    "        return tensor\n",
    "    elif tensor.ndim == 3:\n",
    "        if not vit_like:\n",
    "            raise ValueError(f\"The tensor shape is {tensor.shape}, if it's a \"\n",
    "                             'vit-like backbone, please specify `--vit-like`.')\n",
    "        # For (B, L, C)\n",
    "        num_extra_tokens = num_extra_tokens or getattr(\n",
    "            model.backbone, 'num_extra_tokens', 1)\n",
    "\n",
    "        tensor = tensor[:, num_extra_tokens:, :]\n",
    "        # get heat_map_height and heat_map_width, preset input is a square\n",
    "        heat_map_area = tensor.size()[1]\n",
    "        height, width = to_2tuple(int(math.sqrt(heat_map_area)))\n",
    "        assert height * height == heat_map_area, \\\n",
    "            (f\"The input feature's length ({heat_map_area+num_extra_tokens}) \"\n",
    "             f'minus num-extra-tokens ({num_extra_tokens}) is {heat_map_area},'\n",
    "             ' which is not a perfect square number. Please check if you used '\n",
    "             'a wrong num-extra-tokens.')\n",
    "        # (B, L, C) -> (B, H, W, C)\n",
    "        result = tensor.reshape(tensor.size(0), height, width, tensor.size(2))\n",
    "        # (B, H, W, C) -> (B, C, H, W)\n",
    "        result = result.permute(0, 3, 1, 2)\n",
    "        return result\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported tensor shape {tensor.shape}.')\n",
    "\n",
    "\n",
    "def init_cam(method, model, target_layers, use_cuda, reshape_transform):\n",
    "    \"\"\"Construct the CAM object once, In order to be compatible with\n",
    "    mmpretrain, here we modify the ActivationsAndGradients object.\"\"\"\n",
    "    GradCAM_Class = METHOD_MAP[method.lower()]\n",
    "    cam = GradCAM_Class(\n",
    "        model=model, target_layers=target_layers)\n",
    "    # Release the original hooks in ActivationsAndGradients to use\n",
    "    # ActivationsAndGradients.\n",
    "    cam.activations_and_grads.release()\n",
    "    cam.activations_and_grads = ActivationsAndGradients(\n",
    "        cam.model, cam.target_layers, reshape_transform)\n",
    "\n",
    "    return cam\n",
    "\n",
    "\n",
    "def get_layer(layer_str, model):\n",
    "    \"\"\"get model layer from given str.\"\"\"\n",
    "    for name, layer in model.named_modules():\n",
    "        if name == layer_str:\n",
    "            return layer\n",
    "    raise AttributeError(\n",
    "        f'Cannot get the layer \"{layer_str}\". Please choose from: \\n' +\n",
    "        '\\n'.join(name for name, _ in model.named_modules()))\n",
    "\n",
    "\n",
    "def show_cam_grad(grayscale_cam, src_img, title, out_path=None):\n",
    "    \"\"\"fuse src_img and grayscale_cam and show or save.\"\"\"\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    src_img = np.float32(src_img) / 255\n",
    "    visualization_img = show_cam_on_image(\n",
    "        src_img, grayscale_cam, use_rgb=False)\n",
    "\n",
    "    if out_path:\n",
    "        mmcv.imwrite(visualization_img, str(out_path))\n",
    "    else:\n",
    "        mmcv.imshow(visualization_img, win_name=title)\n",
    "\n",
    "\n",
    "def get_default_target_layers(model, vit_like=False, num_extra_tokens=None):\n",
    "    \"\"\"get default target layers from given model, here choose nrom type layer\n",
    "    as default target layer.\"\"\"\n",
    "    norm_layers = [\n",
    "        (name, layer)\n",
    "        for name, layer in model.backbone.named_modules(prefix='backbone')\n",
    "        if is_norm(layer)\n",
    "    ]\n",
    "    if vit_like:\n",
    "        # For ViT models, the final classification is done on the class token.\n",
    "        # And the patch tokens and class tokens won't interact each other after\n",
    "        # the final attention layer. Therefore, we need to choose the norm\n",
    "        # layer before the last attention layer.\n",
    "        num_extra_tokens = num_extra_tokens or getattr(\n",
    "            model.backbone, 'num_extra_tokens', 1)\n",
    "\n",
    "        # models like swin have no attr 'out_type', set out_type to avg_featmap\n",
    "        out_type = getattr(model.backbone, 'out_type', 'avg_featmap')\n",
    "        if out_type == 'cls_token' or num_extra_tokens > 0:\n",
    "            # Assume the backbone feature is class token.\n",
    "            name, layer = norm_layers[-3]\n",
    "            print('Automatically choose the last norm layer before the '\n",
    "                  f'final attention block \"{name}\" as the target layer.')\n",
    "            return [layer]\n",
    "\n",
    "    # For CNN models, use the last norm layer as the target-layer\n",
    "    name, layer = norm_layers[-1]\n",
    "    print('Automatically choose the last norm layer '\n",
    "          f'\"{name}\" as the target layer.')\n",
    "    return [layer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "config = \"configs/from_imagenet/efficiennet-b3-fold_0_4gencam.py\"\n",
    "checkpoint = \"work_folder/from_imagenet_4gencam/efficient-b3-100/best_pfbeta_epoch_98.pth\"\n",
    "img_dir = \"../datasets/mmbreast/\"\n",
    "\n",
    "device = \"cpu\"\n",
    "preview_model = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gradcam++': <class 'pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus'>, 'gradcam': <class 'pytorch_grad_cam.grad_cam.GradCAM'>, 'hirescam': <class 'pytorch_grad_cam.hirescam.HiResCAM'>, 'gradcamelementwise': <class 'pytorch_grad_cam.grad_cam_elementwise.GradCAMElementWise'>, 'ablationcam': <class 'pytorch_grad_cam.ablation_cam.AblationCAM'>, 'xgradcam': <class 'pytorch_grad_cam.xgrad_cam.XGradCAM'>, 'gradcamplusplus': <class 'pytorch_grad_cam.grad_cam_plusplus.GradCAMPlusPlus'>, 'scorecam': <class 'pytorch_grad_cam.score_cam.ScoreCAM'>, 'layercam': <class 'pytorch_grad_cam.layer_cam.LayerCAM'>, 'eigencam': <class 'pytorch_grad_cam.eigen_cam.EigenCAM'>, 'eigengradcam': <class 'pytorch_grad_cam.eigen_grad_cam.EigenGradCAM'>, 'randomcam': <class 'pytorch_grad_cam.random_cam.RandomCAM'>, 'fullgrad': <class 'pytorch_grad_cam.fullgrad_cam.FullGrad'>}\n"
     ]
    }
   ],
   "source": [
    "print(METHOD_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_like = False\n",
    "num_extra_tokens = None\n",
    "method = 'hirescam' #  'gradcam++' GradCAM hirescam gradcamelementwise ablationcam xgradcam gradcamplusplus scorecam layercam eigencam eigengradcam randomcam fullgrad\n",
    "target_category = []\n",
    "eigen_smooth = False\n",
    "aug_smooth = False\n",
    "save_path = \"./grad_cam.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patient_id': 'C_0003_1', 'image_id': 'C_0003_1|RIGHT|MLO', 'view': 'MLO', 'laterality': 'R', 'density': 'B', 'age': 46.0, 'ddsm_ori_status': 'Cancer', 'cancer': 1, 'split': 2.0, 'dataset': 'miniddsm'}\n"
     ]
    }
   ],
   "source": [
    "cfg = Config.fromfile(config)\n",
    "data_list =  DATASETS.build(cfg.test_dataloader.dataset).load_data_list()\n",
    "img_skip = 4\n",
    "skipped = 0\n",
    "\n",
    "for item in data_list:\n",
    "    if item['cancer'] == 1:\n",
    "        skipped += 1\n",
    "    if skipped == img_skip:\n",
    "        break\n",
    "print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: work_folder/from_imagenet_4gencam/efficient-b3-100/best_pfbeta_epoch_98.pth\n",
      "BreastCancerAuxCls(\n",
      "  (data_preprocessor): ClsDataPreprocessor()\n",
      "  (backbone): EfficientNet(\n",
      "    (layers): ModuleList(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2dAdaptivePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): Swish()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(40, 40, kernel_size=(3, 3), stride=(1, 1), groups=40, bias=False)\n",
      "            (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
      "            (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
      "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(192, 192, kernel_size=(5, 5), stride=(2, 2), groups=192, bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
      "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
      "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(288, 288, kernel_size=(3, 3), stride=(2, 2), groups=288, bias=False)\n",
      "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (4): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (5): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(576, 576, kernel_size=(5, 5), stride=(1, 1), groups=576, bias=False)\n",
      "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (6): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
      "            (bn): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (7): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
      "            (bn): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (8): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
      "            (bn): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (9): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
      "            (bn): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(816, 816, kernel_size=(5, 5), stride=(2, 2), groups=816, bias=False)\n",
      "            (bn): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
      "            (bn): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
      "            (bn): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
      "            (bn): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (4): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
      "            (bn): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (5): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
      "            (bn): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (6): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(1392, 1392, kernel_size=(3, 3), stride=(1, 1), groups=1392, bias=False)\n",
      "            (bn): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (7): InvertedResidual(\n",
      "          (drop_path): Identity()\n",
      "          (expand_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
      "            (bn): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (se): SELayer(\n",
      "            (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv1): ConvModule(\n",
      "              (conv): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (conv2): ConvModule(\n",
      "              (conv): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activate): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (linear_conv): ConvModule(\n",
      "            (conv): Conv2dAdaptivePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): ConvModule(\n",
      "        (conv): Conv2dAdaptivePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): Swish()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': ['_BatchNorm', 'GroupNorm'], 'val': 1}]\n",
      "  (neck): GlobalAveragePooling(\n",
      "    (gap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (head): LinearClsHead(\n",
      "    (loss_module): SoftmaxEQLLoss()\n",
      "    (fc): Linear(in_features=1536, out_features=2, bias=True)\n",
      "  )\n",
      "  (nn_BIRADS): Linear(in_features=1536, out_features=5, bias=True)\n",
      "  (nn_sigmoid): Linear(in_features=1536, out_features=3, bias=True)\n",
      "  (ce_loss): CrossEntropyLoss()\n",
      "  (sigmoid_loss): BCEWithLogitsLoss()\n",
      "  (BIRADS_lossfn): SoftmaxEQLLoss()\n",
      "  (diff_lossfn): SoftmaxEQLLoss()\n",
      "  (density_lossfn): SoftmaxEQLLoss()\n",
      ")\n",
      "init_cfg={'type': 'TruncNormal', 'layer': ['Conv2d', 'Linear'], 'std': 0.02, 'bias': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/islab/DATA/venv/mmbreast/lib/python3.12/site-packages/mmengine/runner/checkpoint.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, map_location=map_location)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model from a config file and a checkpoint file\n",
    "model: nn.Module = get_model(cfg, checkpoint, device=device)\n",
    "if preview_model:\n",
    "    print(model)\n",
    "\n",
    "# apply transform and perpare data\n",
    "transforms = Compose(\n",
    "    [TRANSFORMS.build(t) for t in cfg.test_dataloader.dataset.pipeline])\n",
    "data = transforms(item)\n",
    "src_img = copy.deepcopy(data['inputs']).numpy().transpose(1, 2, 0)\n",
    "data = model.data_preprocessor(default_collate([data]), False)\n",
    "target_layers = [\"backbone.layers.6.activate\"]\n",
    "# build target layers\n",
    "if target_layers:\n",
    "    target_layers = [\n",
    "        get_layer(layer, model) for layer in target_layers\n",
    "    ]\n",
    "else:\n",
    "    target_layers = get_default_target_layers(model, vit_like, num_extra_tokens)\n",
    "\n",
    "# init a cam grad calculator\n",
    "use_cuda = ('cuda' in device)\n",
    "cam = init_cam(method, model, target_layers, use_cuda,\n",
    "                partial(reshape_transform, model=model, vit_like=vit_like, num_extra_tokens=num_extra_tokens))\n",
    "\n",
    "# warp the target_category with ClassifierOutputTarget in grad_cam>=1.3.7,\n",
    "# to fix the bug in #654.\n",
    "targets = None\n",
    "if target_category:\n",
    "    grad_cam_v = pkg_resources.get_distribution('grad_cam').version\n",
    "    if digit_version(grad_cam_v) >= digit_version('1.3.7'):\n",
    "        from pytorch_grad_cam.utils.model_targets import \\\n",
    "            ClassifierOutputTarget\n",
    "        targets = [ClassifierOutputTarget(c) for c in target_category]\n",
    "    else:\n",
    "        targets = target_category\n",
    "\n",
    "# calculate cam grads and show|save the visualization image\n",
    "grayscale_cam = cam(\n",
    "    data['inputs'],\n",
    "    targets,\n",
    "    eigen_smooth=eigen_smooth,\n",
    "    aug_smooth=aug_smooth)\n",
    "show_cam_grad(\n",
    "    grayscale_cam, src_img, title=method, out_path=save_path)\n",
    "mmcv.imwrite(src_img, str(\"./input.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmbreast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
