{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_155394/2115944803.py:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n",
      "/home/islab/DATA/venv/mmbreast/lib/python3.12/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import argparse\n",
    "import copy\n",
    "import math\n",
    "import pkg_resources\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from mmcv.transforms import Compose\n",
    "from mmengine.config import Config, DictAction\n",
    "from mmengine.dataset import default_collate\n",
    "from mmengine.utils import to_2tuple\n",
    "from mmengine.utils.dl_utils import is_norm\n",
    "\n",
    "from mmpretrain import digit_version\n",
    "from mmpretrain.apis import get_model\n",
    "from mmpretrain.registry import TRANSFORMS\n",
    "\n",
    "try:\n",
    "    import pytorch_grad_cam as cam\n",
    "    from pytorch_grad_cam.activations_and_gradients import \\\n",
    "        ActivationsAndGradients\n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "except ImportError:\n",
    "    raise ImportError('Please run `pip install \"grad-cam>=1.3.6\"` to install '\n",
    "                      '3rd party package pytorch_grad_cam.')\n",
    "\n",
    "# Alias name\n",
    "METHOD_MAP = {\n",
    "    'gradcam++': cam.GradCAMPlusPlus,\n",
    "}\n",
    "METHOD_MAP.update({\n",
    "    cam_class.__name__.lower(): cam_class\n",
    "    for cam_class in cam.base_cam.BaseCAM.__subclasses__()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reshape_transform(tensor, model, args):\n",
    "    \"\"\"Build reshape_transform for `cam.activations_and_grads`, which is\n",
    "    necessary for ViT-like networks.\"\"\"\n",
    "    # ViT_based_Transformers have an additional clstoken in features\n",
    "    if tensor.ndim == 4:\n",
    "        # For (B, C, H, W)\n",
    "        return tensor\n",
    "    elif tensor.ndim == 3:\n",
    "        if not args.vit_like:\n",
    "            raise ValueError(f\"The tensor shape is {tensor.shape}, if it's a \"\n",
    "                             'vit-like backbone, please specify `--vit-like`.')\n",
    "        # For (B, L, C)\n",
    "        num_extra_tokens = args.num_extra_tokens or getattr(\n",
    "            model.backbone, 'num_extra_tokens', 1)\n",
    "\n",
    "        tensor = tensor[:, num_extra_tokens:, :]\n",
    "        # get heat_map_height and heat_map_width, preset input is a square\n",
    "        heat_map_area = tensor.size()[1]\n",
    "        height, width = to_2tuple(int(math.sqrt(heat_map_area)))\n",
    "        assert height * height == heat_map_area, \\\n",
    "            (f\"The input feature's length ({heat_map_area+num_extra_tokens}) \"\n",
    "             f'minus num-extra-tokens ({num_extra_tokens}) is {heat_map_area},'\n",
    "             ' which is not a perfect square number. Please check if you used '\n",
    "             'a wrong num-extra-tokens.')\n",
    "        # (B, L, C) -> (B, H, W, C)\n",
    "        result = tensor.reshape(tensor.size(0), height, width, tensor.size(2))\n",
    "        # (B, H, W, C) -> (B, C, H, W)\n",
    "        result = result.permute(0, 3, 1, 2)\n",
    "        return result\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported tensor shape {tensor.shape}.')\n",
    "\n",
    "\n",
    "def init_cam(method, model, target_layers, use_cuda, reshape_transform):\n",
    "    \"\"\"Construct the CAM object once, In order to be compatible with\n",
    "    mmpretrain, here we modify the ActivationsAndGradients object.\"\"\"\n",
    "    GradCAM_Class = METHOD_MAP[method.lower()]\n",
    "    cam = GradCAM_Class(\n",
    "        model=model, target_layers=target_layers, use_cuda=use_cuda)\n",
    "    # Release the original hooks in ActivationsAndGradients to use\n",
    "    # ActivationsAndGradients.\n",
    "    cam.activations_and_grads.release()\n",
    "    cam.activations_and_grads = ActivationsAndGradients(\n",
    "        cam.model, cam.target_layers, reshape_transform)\n",
    "\n",
    "    return cam\n",
    "\n",
    "\n",
    "def get_layer(layer_str, model):\n",
    "    \"\"\"get model layer from given str.\"\"\"\n",
    "    for name, layer in model.named_modules():\n",
    "        if name == layer_str:\n",
    "            return layer\n",
    "    raise AttributeError(\n",
    "        f'Cannot get the layer \"{layer_str}\". Please choose from: \\n' +\n",
    "        '\\n'.join(name for name, _ in model.named_modules()))\n",
    "\n",
    "\n",
    "def show_cam_grad(grayscale_cam, src_img, title, out_path=None):\n",
    "    \"\"\"fuse src_img and grayscale_cam and show or save.\"\"\"\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    src_img = np.float32(src_img) / 255\n",
    "    visualization_img = show_cam_on_image(\n",
    "        src_img, grayscale_cam, use_rgb=False)\n",
    "\n",
    "    if out_path:\n",
    "        mmcv.imwrite(visualization_img, str(out_path))\n",
    "    else:\n",
    "        mmcv.imshow(visualization_img, win_name=title)\n",
    "\n",
    "\n",
    "def get_default_target_layers(model, args):\n",
    "    \"\"\"get default target layers from given model, here choose nrom type layer\n",
    "    as default target layer.\"\"\"\n",
    "    norm_layers = [\n",
    "        (name, layer)\n",
    "        for name, layer in model.backbone.named_modules(prefix='backbone')\n",
    "        if is_norm(layer)\n",
    "    ]\n",
    "    if args.vit_like:\n",
    "        # For ViT models, the final classification is done on the class token.\n",
    "        # And the patch tokens and class tokens won't interact each other after\n",
    "        # the final attention layer. Therefore, we need to choose the norm\n",
    "        # layer before the last attention layer.\n",
    "        num_extra_tokens = args.num_extra_tokens or getattr(\n",
    "            model.backbone, 'num_extra_tokens', 1)\n",
    "\n",
    "        # models like swin have no attr 'out_type', set out_type to avg_featmap\n",
    "        out_type = getattr(model.backbone, 'out_type', 'avg_featmap')\n",
    "        if out_type == 'cls_token' or num_extra_tokens > 0:\n",
    "            # Assume the backbone feature is class token.\n",
    "            name, layer = norm_layers[-3]\n",
    "            print('Automatically choose the last norm layer before the '\n",
    "                  f'final attention block \"{name}\" as the target layer.')\n",
    "            return [layer]\n",
    "\n",
    "    # For CNN models, use the last norm layer as the target-layer\n",
    "    name, layer = norm_layers[-1]\n",
    "    print('Automatically choose the last norm layer '\n",
    "          f'\"{name}\" as the target layer.')\n",
    "    return [layer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"configs/from_imagenet/convnextv2-atto-fold_0_4gencam.py\"\n",
    "checkpoint = \"work_dirs/convnextv2-atto-fold_0_4gencam/best_pfbeta_epoch_34.pth\"\n",
    "img = \"../datasets/mmbreast/\"\n",
    "\n",
    "device = \"cpu\"\n",
    "preview_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'checkpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigs/from_imagenet/convnextv2-atto-fold_0_4gencam.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcheckpoint\u001b[49m\n\u001b[1;32m      3\u001b[0m cfg \u001b[38;5;241m=\u001b[39m Config\u001b[38;5;241m.\u001b[39mfromfile(config)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# build the model from a config file and a checkpoint file\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'checkpoint' is not defined"
     ]
    }
   ],
   "source": [
    "cfg = Config.fromfile(config)\n",
    "\n",
    "# build the model from a config file and a checkpoint file\n",
    "model: nn.Module = get_model(cfg, checkpoint, device=device)\n",
    "if preview_model:\n",
    "    print(model)\n",
    "\n",
    "# apply transform and perpare data\n",
    "transforms = Compose(\n",
    "    [TRANSFORMS.build(t) for t in cfg.test_dataloader.dataset.pipeline])\n",
    "data = transforms({'img_path': args.img})\n",
    "src_img = copy.deepcopy(data['inputs']).numpy().transpose(1, 2, 0)\n",
    "data = model.data_preprocessor(default_collate([data]), False)\n",
    "\n",
    "# build target layers\n",
    "if args.target_layers:\n",
    "    target_layers = [\n",
    "        get_layer(layer, model) for layer in args.target_layers\n",
    "    ]\n",
    "else:\n",
    "    target_layers = get_default_target_layers(model, args)\n",
    "\n",
    "# init a cam grad calculator\n",
    "use_cuda = ('cuda' in args.device)\n",
    "cam = init_cam(args.method, model, target_layers, use_cuda,\n",
    "                partial(reshape_transform, model=model, args=args))\n",
    "\n",
    "# warp the target_category with ClassifierOutputTarget in grad_cam>=1.3.7,\n",
    "# to fix the bug in #654.\n",
    "targets = None\n",
    "if args.target_category:\n",
    "    grad_cam_v = pkg_resources.get_distribution('grad_cam').version\n",
    "    if digit_version(grad_cam_v) >= digit_version('1.3.7'):\n",
    "        from pytorch_grad_cam.utils.model_targets import \\\n",
    "            ClassifierOutputTarget\n",
    "        targets = [ClassifierOutputTarget(c) for c in args.target_category]\n",
    "    else:\n",
    "        targets = args.target_category\n",
    "\n",
    "# calculate cam grads and show|save the visualization image\n",
    "grayscale_cam = cam(\n",
    "    data['inputs'],\n",
    "    targets,\n",
    "    eigen_smooth=args.eigen_smooth,\n",
    "    aug_smooth=args.aug_smooth)\n",
    "show_cam_grad(\n",
    "    grayscale_cam, src_img, title=args.method, out_path=args.save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmbreast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
